{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import time  \n",
    "import numpy as np\n",
    "import copy\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been broken into 16 pieces\n"
     ]
    }
   ],
   "source": [
    "# Chunking the csv to 50K rows to import it faster. \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "chunk_size = 50000\n",
    "batch_no=1\n",
    "for chunk in pd.read_csv(\"C:/Users/sivapr/Documents/Cops/ML Project/PC MC TPH Model/Chunking Base files/PC_MC_RD_(Wk'09-Wk'23)_Untouched.csv\", chunksize=chunk_size):\n",
    "    chunk.to_csv('C:/Users/sivapr/Documents/Cops/ML Project/PC MC TPH Model/Chunking Base files/PC_MC_RD_Chunk' + str(batch_no) + '.csv' , index= False)\n",
    "    batch_no += 1 \n",
    "\n",
    "print(f'The file has been broken into {batch_no-1} pieces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The 16 files have been imported, time taken is 1.25 mins\n"
     ]
    }
   ],
   "source": [
    "# Importing all the chunks into individual dataframe.\n",
    "\n",
    "df=pd.DataFrame()\n",
    "for i in np.arange(1,batch_no):\n",
    "    temp_df = pd.read_csv('C:/Users/sivapr/Documents/Cops/ML Project/PC MC TPH Model/Chunking Base files/PC_MC_RD_Chunk'+ str(i) + '.csv')\n",
    "    df = pd.concat([df,temp_df]) \n",
    "\n",
    "df.reset_index(drop=True)\n",
    "\n",
    "mid1 = time.time()\n",
    "time_taken = ((mid1-start)/60)\n",
    "print(f' The {batch_no-1} files have been imported, time taken is {round(time_taken,2)} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The untouched dataframe shape is (789464, 99)\n"
     ]
    }
   ],
   "source": [
    "# Understanding the shape of the data\n",
    "\n",
    "x = df.shape\n",
    "print('The untouched dataframe shape is', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['metric', 'selected_date', 'week', 'month', 'quarter', 'year',\n",
       "       'program', 'node', 'userid', 'clientworkitemid', 'asin', 'countrycode',\n",
       "       'labeltype', 'time_zone', 'beagle_workitem_workstreamname',\n",
       "       'beagle_node', 'beagle_workitem_workitemstatus',\n",
       "       'beagle_workitem_isdeleted', 'create_time', 'create_time2',\n",
       "       'create_date2', 'target_time', 'target_date', 'destinationcountrycode',\n",
       "       'sub_program', 'project', 'ingestionsourcetype', 'clusterid',\n",
       "       'classify_batchid', 'classify_batchstatus', 'classify_workstream',\n",
       "       'classify_assignedat', 'classify_assignedat2',\n",
       "       'classify_assignedat_date2', 'classify_completedat',\n",
       "       'classify_completedat2', 'classify_completedat_date2',\n",
       "       'classify_lastupdatedat', 'classify_lastupdatedat2',\n",
       "       'classify_lastupdatedat_date2', 'classify_userid',\n",
       "       'classify_supervisor_login_name', 'classify_country', 'classify_city',\n",
       "       'classification', 'classification_type', 'mc_remarks', 'audit_batchid',\n",
       "       'audit_batchstatus', 'audit_workstream', 'audit_assignedat',\n",
       "       'audit_assignedat2', 'audit_assignedat_date2', 'audit_completedat',\n",
       "       'audit_completedat2', 'audit_completedat_date2', 'audit_lastupdatedat',\n",
       "       'audit_lastupdatedat2', 'audit_lastupdatedat_date2', 'audit_userid',\n",
       "       'audit_supervisor_login_name', 'audit_country', 'audit_city',\n",
       "       'qa_decision', 'qa_error_type', 'qa_remarks', 'audit_classify_batchid',\n",
       "       'qa_classification', 'qa_classification_type', 'audit_sample_status',\n",
       "       'sme_classify_batchid', 'sme_classify_batchstatus',\n",
       "       'sme_classify_workstream', 'sme_classify_assignedat',\n",
       "       'sme_classify_assignedat2', 'sme_classify_assignedat_date2',\n",
       "       'sme_classify_completedat', 'sme_classify_completedat2',\n",
       "       'sme_classify_completedat_date2', 'sme_classify_lastupdatedat',\n",
       "       'sme_classify_lastupdatedat2', 'sme_classify_lastupdatedat_date2',\n",
       "       'sme_classify_userid', 'sme_classify_supervisor_login_name',\n",
       "       'sme_classify_country', 'sme_classify_city', 'sme_classification',\n",
       "       'sme_selectedstatus', 'sme_selectederror', 'sme_remarks',\n",
       "       'client_classification', 'client_remarks', 'r1_workstream',\n",
       "       'r2_workstream', 'beagle_workitem_gl', 'classify_n_pts',\n",
       "       'audit_classify_n_pts', 'sme_classify_n_pts', 'snapshot_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting the rows and columns as max to review all required line items\n",
    "bold=\"\\033[1m\"\n",
    "pd.set_option('max_rows', None)\n",
    "pd.set_option(\"max_columns\", None)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the copy of untouched dataframe in a different memory\n",
    "\n",
    "df_copy = copy.deepcopy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the unnecessary columns\n",
    "\n",
    "cols_to_drop = ['selected_date','month','quarter','userid','clientworkitemid','countrycode','labeltype','time_zone','beagle_workitem_workitemstatus',\n",
    "               'beagle_workitem_isdeleted','create_time','create_time2','create_date2','target_time',\n",
    "               'target_date','sub_program','ingestionsourcetype','classify_batchstatus','classify_assignedat',\n",
    "                'classify_assignedat2', 'classify_completedat','classify_completedat2','classify_lastupdatedat',\n",
    "               'classify_lastupdatedat_date2','classify_country','classify_lastupdatedat2','audit_batchid', 'audit_batchstatus', 'audit_workstream',\n",
    "               'audit_assignedat', 'audit_assignedat2', 'audit_assignedat_date2','audit_completedat', 'audit_completedat2',\n",
    "                'audit_completedat_date2','audit_lastupdatedat', 'audit_lastupdatedat2', 'audit_lastupdatedat_date2',\n",
    "                'audit_userid','audit_supervisor_login_name', 'audit_country', 'audit_city','qa_decision', 'qa_error_type',\n",
    "                'qa_remarks', 'audit_classify_batchid','qa_classification', 'qa_classification_type', 'audit_sample_status',\n",
    "               'sme_classify_batchid', 'sme_classify_batchstatus','sme_classify_workstream', 'sme_classify_assignedat',\n",
    "                 'sme_classify_assignedat2', 'sme_classify_assignedat_date2','sme_classify_completedat', \n",
    "                'sme_classify_completedat2','sme_classify_completedat_date2', 'sme_classify_lastupdatedat',\n",
    "                'sme_classify_lastupdatedat2', 'sme_classify_lastupdatedat_date2','sme_classify_userid',\n",
    "                'sme_classify_supervisor_login_name','sme_classify_country', 'sme_classify_city', 'sme_classification',\n",
    "                'sme_selectedstatus', 'sme_selectederror', 'sme_remarks','client_classification', 'client_remarks',\n",
    "                'r1_workstream','r2_workstream','audit_classify_n_pts', 'sme_classify_n_pts', 'snapshot_day']\n",
    "\n",
    "df.drop(columns=cols_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.destinationcountrycode.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated dataframe shape is (789464, 23)\n",
      "The number of columns dropped are 76\n",
      "The number of rows dropped are 0\n"
     ]
    }
   ],
   "source": [
    "# Analysing the data shape and reviewing the dropped rows and column counts\n",
    "\n",
    "y = df.shape\n",
    "print('The updated dataframe shape is', y)\n",
    "dropped_col = (x[1] - y[1])\n",
    "dropped_rows = (x[0] - y[0])\n",
    "print('The number of columns dropped are', dropped_col)\n",
    "print('The number of rows dropped are', dropped_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unnecessary string from the week column and converting it to an integer.\n",
    "df['week'] = (df.week.apply(lambda x: x.replace('2021-',''))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 16, 19, 18, 14, 13, 15, 11, 12, 10,  9, 20, 21, 23, 22])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reviewing the unique weeks.\n",
    "display(df.week.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pivot table/crosstab to have better understanding of the data.\n",
    "\n",
    "df_cnt_pivot = pd.crosstab(df['week'],df['node'],margins=True,margins_name='Grand Total',normalize=False)\n",
    "df_cnt_pivot.reset_index(drop=False, inplace=True)\n",
    "df_freq_pivot = pd.crosstab(df['week'],df['node'],margins=True,margins_name='Grand Total',normalize=True)\n",
    "df_freq_pivot.reset_index(drop=False, inplace=True)\n",
    "df_cnt_pivot['AMM_dist%'] = round(df_cnt_pivot['AMM']/df_cnt_pivot['Grand Total'],3)\n",
    "df_cnt_pivot['BLR_dist%'] = round(df_cnt_pivot['BLR']/df_cnt_pivot['Grand Total'],3)\n",
    "df_cnt_pivot['SZX_dist%'] = round(df_cnt_pivot['SZX']/df_cnt_pivot['Grand Total'],3)\n",
    "df_cnt_pivot = df_cnt_pivot.reindex(columns=['week', 'AMM', 'BLR', 'SZX', 'AMM_dist%', 'BLR_dist%','SZX_dist%','Grand Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mASIN Count & Node level data\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>node</th>\n",
       "      <th>week</th>\n",
       "      <th>AMM</th>\n",
       "      <th>BLR</th>\n",
       "      <th>SZX</th>\n",
       "      <th>AMM_dist%</th>\n",
       "      <th>BLR_dist%</th>\n",
       "      <th>SZX_dist%</th>\n",
       "      <th>Grand Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>3945</td>\n",
       "      <td>40765</td>\n",
       "      <td>362</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.008</td>\n",
       "      <td>45072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>9175</td>\n",
       "      <td>34322</td>\n",
       "      <td>385</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.009</td>\n",
       "      <td>43882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>4785</td>\n",
       "      <td>29561</td>\n",
       "      <td>395</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.011</td>\n",
       "      <td>34741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>8933</td>\n",
       "      <td>37201</td>\n",
       "      <td>398</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.009</td>\n",
       "      <td>46532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>8588</td>\n",
       "      <td>45530</td>\n",
       "      <td>233</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.004</td>\n",
       "      <td>54351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>22650</td>\n",
       "      <td>58310</td>\n",
       "      <td>245</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.003</td>\n",
       "      <td>81205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>5006</td>\n",
       "      <td>50051</td>\n",
       "      <td>203</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.004</td>\n",
       "      <td>55260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>3882</td>\n",
       "      <td>47360</td>\n",
       "      <td>322</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.006</td>\n",
       "      <td>51564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>4232</td>\n",
       "      <td>56773</td>\n",
       "      <td>570</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.009</td>\n",
       "      <td>61575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>5841</td>\n",
       "      <td>55824</td>\n",
       "      <td>174</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.003</td>\n",
       "      <td>61839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>3550</td>\n",
       "      <td>65025</td>\n",
       "      <td>285</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.004</td>\n",
       "      <td>68860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>8513</td>\n",
       "      <td>47877</td>\n",
       "      <td>214</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.004</td>\n",
       "      <td>56604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>6114</td>\n",
       "      <td>22797</td>\n",
       "      <td>170</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.006</td>\n",
       "      <td>29081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "      <td>16390</td>\n",
       "      <td>30704</td>\n",
       "      <td>189</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.004</td>\n",
       "      <td>47283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23</td>\n",
       "      <td>17091</td>\n",
       "      <td>34075</td>\n",
       "      <td>449</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.009</td>\n",
       "      <td>51615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grand Total</td>\n",
       "      <td>128695</td>\n",
       "      <td>656175</td>\n",
       "      <td>4594</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.006</td>\n",
       "      <td>789464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "node         week     AMM     BLR   SZX  AMM_dist%  BLR_dist%  SZX_dist%  \\\n",
       "0               9    3945   40765   362      0.088      0.904      0.008   \n",
       "1              10    9175   34322   385      0.209      0.782      0.009   \n",
       "2              11    4785   29561   395      0.138      0.851      0.011   \n",
       "3              12    8933   37201   398      0.192      0.799      0.009   \n",
       "4              13    8588   45530   233      0.158      0.838      0.004   \n",
       "5              14   22650   58310   245      0.279      0.718      0.003   \n",
       "6              15    5006   50051   203      0.091      0.906      0.004   \n",
       "7              16    3882   47360   322      0.075      0.918      0.006   \n",
       "8              17    4232   56773   570      0.069      0.922      0.009   \n",
       "9              18    5841   55824   174      0.094      0.903      0.003   \n",
       "10             19    3550   65025   285      0.052      0.944      0.004   \n",
       "11             20    8513   47877   214      0.150      0.846      0.004   \n",
       "12             21    6114   22797   170      0.210      0.784      0.006   \n",
       "13             22   16390   30704   189      0.347      0.649      0.004   \n",
       "14             23   17091   34075   449      0.331      0.660      0.009   \n",
       "15    Grand Total  128695  656175  4594      0.163      0.831      0.006   \n",
       "\n",
       "node  Grand Total  \n",
       "0           45072  \n",
       "1           43882  \n",
       "2           34741  \n",
       "3           46532  \n",
       "4           54351  \n",
       "5           81205  \n",
       "6           55260  \n",
       "7           51564  \n",
       "8           61575  \n",
       "9           61839  \n",
       "10          68860  \n",
       "11          56604  \n",
       "12          29081  \n",
       "13          47283  \n",
       "14          51615  \n",
       "15         789464  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mVolume Distribution data\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>node</th>\n",
       "      <th>week</th>\n",
       "      <th>AMM</th>\n",
       "      <th>BLR</th>\n",
       "      <th>SZX</th>\n",
       "      <th>Grand Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grand Total</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "node         week    AMM    BLR    SZX  Grand Total\n",
       "0               9  0.005  0.052  0.000        0.057\n",
       "1              10  0.012  0.043  0.000        0.056\n",
       "2              11  0.006  0.037  0.001        0.044\n",
       "3              12  0.011  0.047  0.001        0.059\n",
       "4              13  0.011  0.058  0.000        0.069\n",
       "5              14  0.029  0.074  0.000        0.103\n",
       "6              15  0.006  0.063  0.000        0.070\n",
       "7              16  0.005  0.060  0.000        0.065\n",
       "8              17  0.005  0.072  0.001        0.078\n",
       "9              18  0.007  0.071  0.000        0.078\n",
       "10             19  0.004  0.082  0.000        0.087\n",
       "11             20  0.011  0.061  0.000        0.072\n",
       "12             21  0.008  0.029  0.000        0.037\n",
       "13             22  0.021  0.039  0.000        0.060\n",
       "14             23  0.022  0.043  0.001        0.065\n",
       "15    Grand Total  0.163  0.831  0.006        1.000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing the pivot table\n",
    "\n",
    "print(bold+'ASIN Count & Node level data'+bold)\n",
    "display(df_cnt_pivot)\n",
    "print(bold+'Volume Distribution data'+bold)\n",
    "display(round(df_freq_pivot,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cluster including batch_id ##\n",
    "\n",
    "#Replacing blanks with Classified status\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['classification_type'] = df['classification_type'].fillna('Classified')\n",
    "\n",
    "#Replacing the the NA cells in cluster\n",
    "count_cluster_col = df['asin'].count()\n",
    "replace_value = pd.Series(np.arange(count_cluster_col))\n",
    "df['clusterid'] = df['clusterid'].fillna(replace_value)\n",
    "\n",
    "# Forming post classification cluster and counting clusters\n",
    "df['clusterid'] = df['clusterid'].apply(str)\n",
    "df['new_clusterid'] = (df['node']).map(str) + (df['classify_assignedat_date2']).map(str) + (df['classify_userid']).map(str) + (df['clusterid']).map(str) + (df['classify_batchid']).map(str) + (df['classification']).map(str)\n",
    "df['cluster_freq'] =df.groupby(by='new_clusterid')['new_clusterid'].transform('count')\n",
    "\n",
    "#Adding seperate columns for all the cluster size\n",
    "cluster_cols_w_batch = []\n",
    "cluster_max_size = 10\n",
    "cluster_range= np.arange(1,cluster_max_size+1)\n",
    "\n",
    "for i in cluster_range:\n",
    "    df.loc[df['cluster_freq'] < i+1,['cluster_g' + str(i)]] = False\n",
    "    lst1='cluster_g' + str(i)\n",
    "    cluster_cols_w_batch.append(lst1)\n",
    "\n",
    "df[cluster_cols_w_batch] = df[cluster_cols_w_batch].fillna(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mcluster% with respect to count variation (with batch)\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    0.347617\n",
       "True     0.652383\n",
       "Name: cluster_g1, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.392696\n",
       "True     0.607304\n",
       "Name: cluster_g2, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.458094\n",
       "True     0.541906\n",
       "Name: cluster_g3, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.501911\n",
       "True     0.498089\n",
       "Name: cluster_g4, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.534364\n",
       "True     0.465636\n",
       "Name: cluster_g5, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.561998\n",
       "True     0.438002\n",
       "Name: cluster_g6, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.58381\n",
       "True     0.41619\n",
       "Name: cluster_g7, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.604219\n",
       "True     0.395781\n",
       "Name: cluster_g8, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.622345\n",
       "True     0.377655\n",
       "Name: cluster_g9, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.638407\n",
       "True     0.361593\n",
       "Name: cluster_g10, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing the cluster% with batch_id for reference.\n",
    "\n",
    "print(bold+'cluster% with respect to count variation (with batch)'+bold)\n",
    "for i in cluster_cols_w_batch:\n",
    "    display(df[i].value_counts(normalize=True,sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cluster excluding batch_id ##\n",
    "\n",
    "df['new_clusterid_wo_batch'] = (df['node']).map(str) + (df['classify_assignedat_date2']).map(str) + (df['classify_userid']).map(str) + (df['clusterid']).map(str) + (df['classification']).map(str)\n",
    "df['cluster_freq_wo_batch'] =df.groupby(by='new_clusterid_wo_batch')['new_clusterid_wo_batch'].transform('count')\n",
    "\n",
    "cluster_cols_wo_batch = []\n",
    "cluster_max_size = 10\n",
    "cluster_range= np.arange(1,cluster_max_size+1)\n",
    "\n",
    "for i in cluster_range:\n",
    "    df.loc[df['cluster_freq_wo_batch'] < i+1,['cluster_wo_batch_g' + str(i)]] = False\n",
    "    lst2='cluster_wo_batch_g' + str(i)\n",
    "    cluster_cols_wo_batch.append(lst2)\n",
    "\n",
    "df[cluster_cols_wo_batch] = df[cluster_cols_wo_batch].fillna(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mcluster% with respect to count variation (without batch)\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    0.346642\n",
       "True     0.653358\n",
       "Name: cluster_wo_batch_g1, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.391606\n",
       "True     0.608394\n",
       "Name: cluster_wo_batch_g2, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.456986\n",
       "True     0.543014\n",
       "Name: cluster_wo_batch_g3, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.500742\n",
       "True     0.499258\n",
       "Name: cluster_wo_batch_g4, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.53315\n",
       "True     0.46685\n",
       "Name: cluster_wo_batch_g5, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.560891\n",
       "True     0.439109\n",
       "Name: cluster_wo_batch_g6, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.582685\n",
       "True     0.417315\n",
       "Name: cluster_wo_batch_g7, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.603104\n",
       "True     0.396896\n",
       "Name: cluster_wo_batch_g8, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.621094\n",
       "True     0.378906\n",
       "Name: cluster_wo_batch_g9, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.637066\n",
       "True     0.362934\n",
       "Name: cluster_wo_batch_g10, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing the cluster% without batch_id for reference.\n",
    "\n",
    "print(bold+'cluster% with respect to count variation (without batch)'+bold)\n",
    "for i in cluster_cols_wo_batch:\n",
    "    display(df[i].value_counts(normalize=True,sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch_id and PT cluster ##\n",
    "\n",
    "df['new_batch_pt_cluster'] = (df['classify_batchid']).map(str) + (df['classification']).map(str)\n",
    "df['cluster_freq_batch_pt'] =df.groupby(by='new_batch_pt_cluster')['new_batch_pt_cluster'].transform('count')\n",
    "\n",
    "cluster_batch_pt = []\n",
    "cluster_max_size = 10\n",
    "cluster_range= np.arange(1,cluster_max_size+1)\n",
    "\n",
    "for i in cluster_range:\n",
    "    df.loc[df['cluster_freq_batch_pt'] < i+1,['batch_pt_cluster_g' + str(i)]] = False\n",
    "    lst4='batch_pt_cluster_g' + str(i)\n",
    "    cluster_batch_pt.append(lst4)\n",
    "\n",
    "df[cluster_batch_pt] = df[cluster_batch_pt].fillna(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mcluster% with respect to count variation with batch_id and PT\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    0.026931\n",
       "True     0.973069\n",
       "Name: batch_pt_cluster_g1, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.046671\n",
       "True     0.953329\n",
       "Name: batch_pt_cluster_g2, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.064858\n",
       "True     0.935142\n",
       "Name: batch_pt_cluster_g3, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.080707\n",
       "True     0.919293\n",
       "Name: batch_pt_cluster_g4, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.094817\n",
       "True     0.905183\n",
       "Name: batch_pt_cluster_g5, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.108786\n",
       "True     0.891214\n",
       "Name: batch_pt_cluster_g6, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.121049\n",
       "True     0.878951\n",
       "Name: batch_pt_cluster_g7, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.133402\n",
       "True     0.866598\n",
       "Name: batch_pt_cluster_g8, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.14503\n",
       "True     0.85497\n",
       "Name: batch_pt_cluster_g9, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.155797\n",
       "True     0.844203\n",
       "Name: batch_pt_cluster_g10, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing the cluster% batch_id and PT  for reference.\n",
    "\n",
    "print(bold+'cluster% with respect to count variation with batch_id and PT'+bold)\n",
    "for i in cluster_batch_pt:\n",
    "    display(df[i].value_counts(normalize=True,sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UK', 'AE', 'US', 'SG', 'CA', 'AU', 'MX', 'BR', 'JP', 'DE', 'ES',\n",
       "       'IT', 'FR'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviewing the unique MPs in the dataset\n",
    "\n",
    "df.destinationcountrycode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding External Research Column using regex\n",
    "df.loc[df['mc_remarks'].str.contains('http|www', flags= re.I, regex=True, na=False),['ext.research_w_amz']] = True\n",
    "df.loc[df['mc_remarks'].str.contains('http|www', flags= re.I, regex=True, na=False) & ~df['mc_remarks'].str.contains('amazon.', flags= re.I, regex=True, na=False),['ext.research_wo_amz']] = True\n",
    "df[['ext.research_w_amz','ext.research_wo_amz']] = df[['ext.research_w_amz','ext.research_wo_amz']].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mexternal_research with amazon links\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    759346\n",
       "True      30118\n",
       "Name: ext.research_w_amz, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.96185\n",
       "True     0.03815\n",
       "Name: ext.research_w_amz, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mexternal_research without amazon links\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    779426\n",
       "True      10038\n",
       "Name: ext.research_wo_amz, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.987285\n",
       "True     0.012715\n",
       "Name: ext.research_wo_amz, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing the external research% for reference.\n",
    "\n",
    "print(\"\\033[1m\"+'external_research with amazon links'+\"\\033[1m\")\n",
    "display(df['ext.research_w_amz'].value_counts(normalize=False, sort=False))\n",
    "display(df['ext.research_w_amz'].value_counts(normalize=True, sort=False))\n",
    "\n",
    "print(\"\\033[1m\"+'external_research without amazon links'+\"\\033[1m\")\n",
    "display(df['ext.research_wo_amz'].value_counts(normalize=False, sort=False))\n",
    "display(df['ext.research_wo_amz'].value_counts(normalize=True, sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  3.,  2.,  4., nan,  5.,  6.,  7.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviewing the unique pts counts in the dataset\n",
    "\n",
    "df.classify_n_pts.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding seperate columns for all the pts size\n",
    "df['classify_n_pts'] = df['classify_n_pts'] .fillna(0)\n",
    "\n",
    "n_pts_cols = []\n",
    "pts_max_size = 7\n",
    "pts_range= np.arange(1,pts_max_size+1)\n",
    "\n",
    "for i in pts_range:\n",
    "    df.loc[df['classify_n_pts'] < i+1,['classify_n_pts_g' + str(i)]] = False\n",
    "    lst3='classify_n_pts_g' + str(i)\n",
    "    n_pts_cols.append(lst3)\n",
    "\n",
    "df[n_pts_cols] = df[n_pts_cols].fillna(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mmulti-pts% with respect to count variation\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    0.91698\n",
       "True     0.08302\n",
       "Name: classify_n_pts_g1, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.977343\n",
       "True     0.022657\n",
       "Name: classify_n_pts_g2, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.997538\n",
       "True     0.002462\n",
       "Name: classify_n_pts_g3, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.999644\n",
       "True     0.000356\n",
       "Name: classify_n_pts_g4, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.999911\n",
       "True     0.000089\n",
       "Name: classify_n_pts_g5, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.999997\n",
       "True     0.000003\n",
       "Name: classify_n_pts_g6, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    1.0\n",
       "Name: classify_n_pts_g7, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing the multi-pts% for reference.\n",
    "\n",
    "print(\"\\033[1m\"+'multi-pts% with respect to count variation'+\"\\033[1m\")\n",
    "for i in n_pts_cols:\n",
    "    display(df[i].value_counts(normalize=True,sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in new_clusterid: 0\n",
      "NaN values in cluster_freq: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking of cluster columns have NaN values\n",
    "\n",
    "print('NaN values in new_clusterid:',df.new_clusterid.isnull().sum())\n",
    "print('NaN values in cluster_freq:',df.cluster_freq.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561607\n",
      "789464\n",
      "0.711\n"
     ]
    }
   ],
   "source": [
    "print(df.mc_remarks.isnull().sum())\n",
    "print(df.shape[0])\n",
    "print(round((df.mc_remarks.isnull().sum())/(df.shape[0]),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Classified', 'Unable To Classify', 'Need Further Assistance',\n",
       "       'Invalid'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviewing the unique classification_type in the dataset\n",
    "\n",
    "df.classification_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new columns for UTC, invalid_NFA and capturing the data. \n",
    "\n",
    "df['unable_to_classify'] = df.classification_type.apply(lambda x: True if x == 'Unable To Classify' else False)\n",
    "df['invalid_NFA'] = df.classification_type.apply(lambda x: True if (x == 'Invalid' or x == 'Need Further Assistance') else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.969412\n",
       "True     0.030588\n",
       "Name: unable_to_classify, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False    0.99579\n",
       "True     0.00421\n",
       "Name: invalid_NFA, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing the UTC and Invalid_NFA for reference.\n",
    "\n",
    "display(df['unable_to_classify'].value_counts(normalize=True))\n",
    "display(df['invalid_NFA'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(789464, 70)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analysing the data shape.\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Assigned week number for AMM and other nodes.\n",
    "df['classify_assignedat_date2'] = pd.to_datetime(df.classify_assignedat_date2, format='%m/%d/%Y')\n",
    "df['weekstartwith-mon'] = df['classify_assignedat_date2'].dt.strftime('%W')\n",
    "df['weekstartwith-sun'] = df['classify_assignedat_date2'].dt.strftime('%U')\n",
    "df.loc[df['node'] != 'AMM',['assigned_week']] = df['weekstartwith-mon']\n",
    "df.loc[df['node'] == 'AMM',['assigned_week']] = df['weekstartwith-sun']\n",
    "del df['weekstartwith-mon'], df['weekstartwith-sun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['assigned_week'] = df['assigned_week'].map(int)\n",
    "df['overflow'] = np.where(df['week'] == df['assigned_week'],True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 16, 15, 19, 18, 14, 13, 12, 11, 10,  9,  8, 20, 21, 23, 22])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['assigned_week'].astype(int).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['UK', 'AE', 'US', 'SG', 'CA', 'AU', 'MX', 'BR', 'JP', 'DE', 'ES',\n",
       "       'IT', 'FR'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.destinationcountrycode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1moverflow asin count\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     763989\n",
       "False     25475\n",
       "Name: overflow, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1moverflow asin% count\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     0.967731\n",
       "False    0.032269\n",
       "Name: overflow, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reviewing count of overflow ASINs\n",
    "\n",
    "print()\n",
    "print(\"\\033[1m\"+'overflow asin count'+\"\\033[1m\")\n",
    "display(df['overflow'].value_counts())\n",
    "print(\"\\033[1m\"+'overflow asin% count'+\"\\033[1m\")\n",
    "display(df['overflow'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['metric', 'week', 'year', 'program', 'node', 'asin',\n",
       "       'beagle_workitem_workstreamname', 'beagle_node',\n",
       "       'destinationcountrycode', 'project', 'clusterid', 'classify_batchid',\n",
       "       'classify_workstream', 'classify_assignedat_date2',\n",
       "       'classify_completedat_date2', 'classify_userid',\n",
       "       'classify_supervisor_login_name', 'classify_city', 'classification',\n",
       "       'classification_type', 'mc_remarks', 'beagle_workitem_gl',\n",
       "       'classify_n_pts', 'new_clusterid', 'cluster_freq', 'cluster_g1',\n",
       "       'cluster_g2', 'cluster_g3', 'cluster_g4', 'cluster_g5', 'cluster_g6',\n",
       "       'cluster_g7', 'cluster_g8', 'cluster_g9', 'cluster_g10',\n",
       "       'new_clusterid_wo_batch', 'cluster_freq_wo_batch',\n",
       "       'cluster_wo_batch_g1', 'cluster_wo_batch_g2', 'cluster_wo_batch_g3',\n",
       "       'cluster_wo_batch_g4', 'cluster_wo_batch_g5', 'cluster_wo_batch_g6',\n",
       "       'cluster_wo_batch_g7', 'cluster_wo_batch_g8', 'cluster_wo_batch_g9',\n",
       "       'cluster_wo_batch_g10', 'new_batch_pt_cluster', 'cluster_freq_batch_pt',\n",
       "       'batch_pt_cluster_g1', 'batch_pt_cluster_g2', 'batch_pt_cluster_g3',\n",
       "       'batch_pt_cluster_g4', 'batch_pt_cluster_g5', 'batch_pt_cluster_g6',\n",
       "       'batch_pt_cluster_g7', 'batch_pt_cluster_g8', 'batch_pt_cluster_g9',\n",
       "       'batch_pt_cluster_g10', 'ext.research_w_amz', 'ext.research_wo_amz',\n",
       "       'classify_n_pts_g1', 'classify_n_pts_g2', 'classify_n_pts_g3',\n",
       "       'classify_n_pts_g4', 'classify_n_pts_g5', 'classify_n_pts_g6',\n",
       "       'classify_n_pts_g7', 'unable_to_classify', 'invalid_NFA',\n",
       "       'assigned_week', 'overflow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['destinationcountrycode'] == 'UK') &  df['classification'].str.contains(r'\\bGeneral_Use\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df.loc[(df['destinationcountrycode'] == 'AE') &  df['classification'].str.contains(r'\\bToys_Non_Electrical_Child\\b|\\bToys_Electrical_Child\\b|\\bChildcare_Articles\\b|\\bLightbulbs\\b|\\bChildren_Products\\b|\\bRegcat_Temp_AE\\b|\\bToys_Child\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df.loc[(df['destinationcountrycode'] == 'US') &  df['classification'].str.contains(r'\\bPowered_Scooters_Child\\b|\\bCarpets_Rugs\\b|\\bPest_Control_Products_Unsupported\\b|\\bPGA_FDA_Radiation\\b|\\bSleepwear_Child\\b|\\bCribs_Non_Full_Sized_Cradles_Infant\\b|\\bOTC_Drugs_Unsupported\\b|\\bEMC_Devices\\b|\\bToys_Child\\b|\\bHelmets_Bicycle\\b|\\bConsumer_Electrical_Batteries\\b|\\bConsumer_Primary_Batteries\\b|\\bChildren_Products\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df.loc[(df['destinationcountrycode'] == 'SG') &  df['classification'].str.contains(r'\\bPacifiers_Infant\\b|\\bBathtubs_Infant\\b|\\bRockers_Infant\\b|\\bHigh_Chairs_Infant\\b|\\bConsumer_Electrical_Products_Unsupported\\b|\\bBathseats_Infant\\b|\\bHelmets_Motorcycle\\b|\\bBicycles_Child\\b|\\bNon_Powered_Scooters_Child\\b|\\bJewelry_Child\\b|\\bPest_Control_Devices_Unsupported\\b|\\bMedical_Devices_Unsupported\\b|\\bToys_General_Use\\b|\\bSports_General_Use\\b|\\bAuto_General_Use\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df.loc[(df['destinationcountrycode'] == 'CA') &  df['classification'].str.contains(r'\\bMattress_Crib_Infant\\b|\\bSunglasses_Child\\b|\\bRefrigerator_Doors\\b|\\bSwings_Infant\\b|\\bMouth_Contact_Products\\b|\\bFlexible_Film_Plastic_Bags\\b|\\bFurniture_Clothing_Storages\\b|\\bPacifiers_Infant\\b|\\bGlass_Doors_and_Enclosures\\b|\\bCarpets_Rugs\\b|\\bHelmets_Sports_Protective\\b|\\bPest_Control_Products_Unsupported\\b|\\bMotor_Vehicle_Charged_Devices\\b|\\bSlings_Infant\\b|\\bCushion_Pillows_Infant\\b|\\bBathseats_Infant\\b|\\bSleepwear_Child\\b|\\bCribs_Non_Full_Sized_Cradles_Infant\\b|\\bBaby_Monitors\\b|\\bBicycles_Child\\b|\\bEMC_Devices\\b|\\bToys_Child\\b|\\bSports_General_Use\\b|\\bHelmets_Bicycle\\b|\\bChildren_Products\\b|\\bTemporary_Unsupported\\b|\\bCE_General_Use\\b|\\bHome_General_Use\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df.loc[(df['destinationcountrycode'] == 'AU') &  df['classification'].str.contains(r'\\bSports_General_Use\\b|\\bSleepwear_Child\\b|\\bRockers_Infant\\b|\\bRattles_Infant\\b|\\bPressure_Equipment\\b|\\bPlants_and_Seeds_Unsupported\\b|\\bPest_Control_Devices_Unsupported\\b|\\bPPE_Cat_1\\b|\\bNon_Powered_Scooters_Child\\b|\\bMedical_Devices_Unsupported\\b|\\bJewelry_Child\\b|\\bHigh_Chairs_Infant\\b|\\bHelmets_Bicycle_Child\\b|\\bFurniture_General_Use\\b|\\bFootwear\\b|\\bFloating_Leisure\\b|\\bFeeding_Bottle_Nipples_Infant\\b|\\bDiving_Equipment\\b|\\bConsumer_Primary_Battery\\b|\\bCarriages_Strollers_Infant\\b|\\bBunk_Beds_Child\\b|\\bBicycles_Child\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df.loc[(df['destinationcountrycode'] == 'MX') &  df['classification'].str.contains(r'\\bHigh_Chairs_Infant\\b|\\bVideogames_Unsupported\\b|\\bDVD_CD_VG\\b|\\bCE_General_Use\\b|\\bCar_Seats_and_Booster_Seats_Child\\b|\\bToys_Child_COFEPRIS\\b|\\bPlumbing\\b|\\bElectronic_Equipment\\b|\\bData_Processing_Equipment\\b|\\bCarriages_Strollers_Infant\\b|\\bWood_Untreated\\b|\\bWood_Treated\\b|\\bVitamins_and_Supplements_Unsupported\\b|\\bFood_Unsupported\\b|\\bChemical_Packaging\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df.loc[(df['destinationcountrycode'] == 'BR') &  df['classification'].str.contains(r'\\bCE_General_Use\\b|\\bOther Equipment General_Use\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df.loc[(df['destinationcountrycode'] == 'JP') &  df['classification'].str.contains(r'\\bBook_Media_Unsupported\\b|\\bPurifiers_Water\\b|\\bHelmets_Motorcycle_Child\\b|\\bElectrical_Components\\b|\\bBedside_Sleepers_Infant\\b|\\bToys_Child_FSL\\b|\\bSpecified_Electrical_Appliances_Materials\\b|\\bNon_Specified_Electrical_Appliances_Materials\\b|\\bHIGH_PRESSURE_GAS_PRODUCTS\\b|\\bShopping_Carts\\b|\\bRear_Mounted_Bicycle_Seats_Child\\b|\\bHousehold_Plastic_Goods\\b|\\bFurniture_Wall_Fixed\\b|\\bFurniture_General_Use_HGL\\b|\\bElectrical_Appliances_Material_Non_PSE\\b|\\bCurtains_Carpets_Public_Space\\b|\\bBunk_Beds_Child\\b|\\bAuto_Safety_Products\\b|\\bAsbestos_Containing_Materials\\b|\\bMattress_Crib_Infant\\b|\\bTricycles_Child\\b|\\bCribs_Full_Sized_Infant\\b|\\bHelmets_Motorcycle_General_Use\\b|\\bBicycles_General_Use\\b|\\bCosmetics_Child\\b|\\bCarpets_Rugs\\b|\\bLaser_Products_General_Use\\b|\\bLuggage\\b|\\bCarriages_Strollers_Infant\\b|\\bSlings_Infant\\b|\\bBibs_Infant\\b|\\bCushion_Pillows_Infant\\b|\\bHigh_Chairs_Infant\\b|\\bChildcare_Articles\\b|\\bBicycles_Child\\b|\\bEMC_Devices\\b|\\bFurniture_General_Use\\b|\\bMedical_Devices_Unsupported\\b|\\bApparel_Child\\b|\\bCosmetics_General_Use\\b|\\bApparel_Accessories\\b|\\bConsumer_Electrical_Products\\b|\\bConsumer_Electrical_Batteries\\b|\\bFootwear\\b|\\bChildren_Products\\b|\\bGeneral_Use\\b|\\bApparel_General_Use\\b|\\bChemicals_Unsupported\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df.loc[(df['destinationcountrycode'] == 'DE') &  df['classification'].str.contains(r'\\bGeneral_Use\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df.loc[(df['destinationcountrycode'] == 'ES') &  df['classification'].str.contains(r'\\bGeneral_Use\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df.loc[(df['destinationcountrycode'] == 'IT') &  df['classification'].str.contains(r'\\bGeneral_Use\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df.loc[(df['destinationcountrycode'] == 'FR') &  df['classification'].str.contains(r'\\bGeneral_Use\\b', flags= re.I, regex=True, na=False),['complexity_h']] = True\n",
    "df[['complexity_h']] = df[['complexity_h']].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.774551\n",
       "True     0.225449\n",
       "Name: complexity_h, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.complexity_h.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact-level Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overflow of ASINs in pivot table.\n",
    "\n",
    "df_overflow_pivot = pd.crosstab(df['week'],df['overflow'],margins=True,margins_name='Grand Total',normalize=False)\n",
    "df_overflow_pivot.reset_index(drop=False, inplace=True)\n",
    "df_overflow_pivot['False%'] = round(df_overflow_pivot[False]/df_cnt_pivot['Grand Total'],3)\n",
    "df_overflow_pivot['True%'] = round(df_overflow_pivot[True]/df_cnt_pivot['Grand Total'],3)\n",
    "df_overflow_pivot = df_overflow_pivot.reindex(columns=['week', False, True, 'False%', 'True%','Grand Total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mOverflow of ASINs at week-level\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>overflow</th>\n",
       "      <th>week</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>False%</th>\n",
       "      <th>True%</th>\n",
       "      <th>Grand Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2265</td>\n",
       "      <td>42807</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.950</td>\n",
       "      <td>45072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1734</td>\n",
       "      <td>42148</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.960</td>\n",
       "      <td>43882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>420</td>\n",
       "      <td>34321</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.988</td>\n",
       "      <td>34741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1680</td>\n",
       "      <td>44852</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.964</td>\n",
       "      <td>46532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1822</td>\n",
       "      <td>52529</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.966</td>\n",
       "      <td>54351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>987</td>\n",
       "      <td>80218</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.988</td>\n",
       "      <td>81205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>2387</td>\n",
       "      <td>52873</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.957</td>\n",
       "      <td>55260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>1381</td>\n",
       "      <td>50183</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.973</td>\n",
       "      <td>51564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>1475</td>\n",
       "      <td>60100</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.976</td>\n",
       "      <td>61575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>3926</td>\n",
       "      <td>57913</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.937</td>\n",
       "      <td>61839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>2805</td>\n",
       "      <td>66055</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.959</td>\n",
       "      <td>68860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>1244</td>\n",
       "      <td>55360</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.978</td>\n",
       "      <td>56604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>178</td>\n",
       "      <td>28903</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.994</td>\n",
       "      <td>29081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "      <td>1867</td>\n",
       "      <td>45416</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.961</td>\n",
       "      <td>47283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23</td>\n",
       "      <td>1304</td>\n",
       "      <td>50311</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.975</td>\n",
       "      <td>51615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grand Total</td>\n",
       "      <td>25475</td>\n",
       "      <td>763989</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.968</td>\n",
       "      <td>789464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "overflow         week  False    True  False%  True%  Grand Total\n",
       "0                   9   2265   42807   0.050  0.950        45072\n",
       "1                  10   1734   42148   0.040  0.960        43882\n",
       "2                  11    420   34321   0.012  0.988        34741\n",
       "3                  12   1680   44852   0.036  0.964        46532\n",
       "4                  13   1822   52529   0.034  0.966        54351\n",
       "5                  14    987   80218   0.012  0.988        81205\n",
       "6                  15   2387   52873   0.043  0.957        55260\n",
       "7                  16   1381   50183   0.027  0.973        51564\n",
       "8                  17   1475   60100   0.024  0.976        61575\n",
       "9                  18   3926   57913   0.063  0.937        61839\n",
       "10                 19   2805   66055   0.041  0.959        68860\n",
       "11                 20   1244   55360   0.022  0.978        56604\n",
       "12                 21    178   28903   0.006  0.994        29081\n",
       "13                 22   1867   45416   0.039  0.961        47283\n",
       "14                 23   1304   50311   0.025  0.975        51615\n",
       "15        Grand Total  25475  763989   0.032  0.968       789464"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Printing overflow data for reference\n",
    "\n",
    "print(\"\\n\\033[1m\"+'Overflow of ASINs at week-level'+\"\\033[1m\")\n",
    "display(df_overflow_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>destinationcountrycode</th>\n",
       "      <th>node</th>\n",
       "      <th>week</th>\n",
       "      <th>classify_userid</th>\n",
       "      <th>no_of_mp</th>\n",
       "      <th>mp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMM</td>\n",
       "      <td>9</td>\n",
       "      <td>ahzaidan</td>\n",
       "      <td>2</td>\n",
       "      <td>AE,UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMM</td>\n",
       "      <td>9</td>\n",
       "      <td>gammohn</td>\n",
       "      <td>2</td>\n",
       "      <td>AE,UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMM</td>\n",
       "      <td>10</td>\n",
       "      <td>fmalabe</td>\n",
       "      <td>2</td>\n",
       "      <td>AE,UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMM</td>\n",
       "      <td>10</td>\n",
       "      <td>gammohn</td>\n",
       "      <td>2</td>\n",
       "      <td>AE,UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMM</td>\n",
       "      <td>11</td>\n",
       "      <td>fmalabe</td>\n",
       "      <td>2</td>\n",
       "      <td>AE,UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AMM</td>\n",
       "      <td>11</td>\n",
       "      <td>gammohn</td>\n",
       "      <td>2</td>\n",
       "      <td>AE,UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMM</td>\n",
       "      <td>12</td>\n",
       "      <td>ahzaidan</td>\n",
       "      <td>2</td>\n",
       "      <td>AE,UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMM</td>\n",
       "      <td>12</td>\n",
       "      <td>fmalabe</td>\n",
       "      <td>2</td>\n",
       "      <td>AE,UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AMM</td>\n",
       "      <td>12</td>\n",
       "      <td>gammohn</td>\n",
       "      <td>2</td>\n",
       "      <td>AE,UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AMM</td>\n",
       "      <td>13</td>\n",
       "      <td>ahzaidan</td>\n",
       "      <td>2</td>\n",
       "      <td>AE,UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "destinationcountrycode node  week classify_userid  no_of_mp     mp\n",
       "0                       AMM     9        ahzaidan         2  AE,UK\n",
       "1                       AMM     9         gammohn         2  AE,UK\n",
       "2                       AMM    10         fmalabe         2  AE,UK\n",
       "3                       AMM    10         gammohn         2  AE,UK\n",
       "4                       AMM    11         fmalabe         2  AE,UK\n",
       "5                       AMM    11         gammohn         2  AE,UK\n",
       "6                       AMM    12        ahzaidan         2  AE,UK\n",
       "7                       AMM    12         fmalabe         2  AE,UK\n",
       "8                       AMM    12         gammohn         2  AE,UK\n",
       "9                       AMM    13        ahzaidan         2  AE,UK"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping MP values\n",
    "\n",
    "df['asin_count'] = 1\n",
    "mp_in_df=df.destinationcountrycode.unique()\n",
    "df_mp_pivot = pd.pivot_table(data=df,index=['node','week','classify_userid'],columns=['destinationcountrycode'],values='asin_count', aggfunc='mean').fillna(0).reset_index()\n",
    "df_mp_pivot['no_of_mp'] = (df_mp_pivot['AE'] + df_mp_pivot['AU'] + df_mp_pivot['BR'] + df_mp_pivot['CA'] + df_mp_pivot['DE'] + df_mp_pivot['ES'] + df_mp_pivot['FR'] + df_mp_pivot['IT'] + df_mp_pivot['JP'] + df_mp_pivot['MX'] + df_mp_pivot['SG'] + df_mp_pivot['UK'] + df_mp_pivot['US']).astype(int)\n",
    "\n",
    "for mkp in mp_in_df:\n",
    "    df_mp_pivot[mkp] = [mkp if x == 1 else 'NaN' for x in df_mp_pivot[mkp]] \n",
    "\n",
    "df_mp_pivot['mp'] = df_mp_pivot['AE'] + ',' + df_mp_pivot['AU'] + ',' + df_mp_pivot['BR'] + ',' + df_mp_pivot['CA'] + ',' + df_mp_pivot['DE'] + ',' + df_mp_pivot['ES'] + ',' + df_mp_pivot['FR'] + ',' + df_mp_pivot['IT'] + ',' + df_mp_pivot['JP'] + ',' + df_mp_pivot['MX'] + ',' + df_mp_pivot['SG'] + ',' + df_mp_pivot['UK'] + ',' + df_mp_pivot['US']\n",
    "df_mp_pivot['mp'] = (df_mp_pivot.mp.apply(lambda x: x.replace(',NaN','').replace('NaN,','')))\n",
    "df_mp_pivot.drop(labels=mp_in_df,axis=1,inplace=True)\n",
    "\n",
    "df_mp_pivot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 9, 8, 5, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mp_pivot.no_of_mp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mFreq Distribution of MPs\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UK                            318\n",
       "CA                             51\n",
       "AE                             50\n",
       "SG                             36\n",
       "AU                             30\n",
       "AE,UK                          24\n",
       "US                             24\n",
       "JP                             23\n",
       "MX                             18\n",
       "BR                             12\n",
       "DE,ES,FR,IT                     2\n",
       "CA,DE,ES,FR,IT,MX,SG,UK,US      1\n",
       "DE,ES,FR,IT,UK                  1\n",
       "CA,DE,ES,FR,IT,MX,UK,US         1\n",
       "ES                              1\n",
       "Name: mp, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UK                            0.537162\n",
       "CA                            0.086149\n",
       "AE                            0.084459\n",
       "SG                            0.060811\n",
       "AU                            0.050676\n",
       "AE,UK                         0.040541\n",
       "US                            0.040541\n",
       "JP                            0.038851\n",
       "MX                            0.030405\n",
       "BR                            0.020270\n",
       "DE,ES,FR,IT                   0.003378\n",
       "CA,DE,ES,FR,IT,MX,SG,UK,US    0.001689\n",
       "DE,ES,FR,IT,UK                0.001689\n",
       "CA,DE,ES,FR,IT,MX,UK,US       0.001689\n",
       "ES                            0.001689\n",
       "Name: mp, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(bold+'Freq Distribution of MPs'+bold)\n",
    "display(df_mp_pivot.mp.value_counts())\n",
    "display(df_mp_pivot.mp.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AE,UK', 'AE', 'UK', 'SG', 'CA', 'AU', 'US', 'MX', 'BR',\n",
       "       'CA,DE,ES,FR,IT,MX,SG,UK,US', 'CA,DE,ES,FR,IT,MX,UK,US',\n",
       "       'DE,ES,FR,IT,UK', 'ES', 'DE,ES,FR,IT', 'JP'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mp_pivot.mp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mp_pivot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>week</th>\n",
       "      <th>classify_userid</th>\n",
       "      <th>asin_count</th>\n",
       "      <th>ext.research_w_amz</th>\n",
       "      <th>ext.research_wo_amz</th>\n",
       "      <th>cluster_g1</th>\n",
       "      <th>cluster_g2</th>\n",
       "      <th>cluster_g3</th>\n",
       "      <th>cluster_g4</th>\n",
       "      <th>cluster_g5</th>\n",
       "      <th>cluster_g6</th>\n",
       "      <th>cluster_g7</th>\n",
       "      <th>cluster_g8</th>\n",
       "      <th>cluster_g9</th>\n",
       "      <th>cluster_g10</th>\n",
       "      <th>unable_to_classify</th>\n",
       "      <th>invalid_NFA</th>\n",
       "      <th>cluster_wo_batch_g1</th>\n",
       "      <th>cluster_wo_batch_g2</th>\n",
       "      <th>cluster_wo_batch_g3</th>\n",
       "      <th>cluster_wo_batch_g4</th>\n",
       "      <th>cluster_wo_batch_g5</th>\n",
       "      <th>cluster_wo_batch_g6</th>\n",
       "      <th>cluster_wo_batch_g7</th>\n",
       "      <th>cluster_wo_batch_g8</th>\n",
       "      <th>cluster_wo_batch_g9</th>\n",
       "      <th>cluster_wo_batch_g10</th>\n",
       "      <th>batch_pt_cluster_g1</th>\n",
       "      <th>batch_pt_cluster_g2</th>\n",
       "      <th>batch_pt_cluster_g3</th>\n",
       "      <th>batch_pt_cluster_g4</th>\n",
       "      <th>batch_pt_cluster_g5</th>\n",
       "      <th>batch_pt_cluster_g6</th>\n",
       "      <th>batch_pt_cluster_g7</th>\n",
       "      <th>batch_pt_cluster_g8</th>\n",
       "      <th>batch_pt_cluster_g9</th>\n",
       "      <th>batch_pt_cluster_g10</th>\n",
       "      <th>classify_n_pts_g1</th>\n",
       "      <th>classify_n_pts_g2</th>\n",
       "      <th>classify_n_pts_g3</th>\n",
       "      <th>classify_n_pts_g4</th>\n",
       "      <th>classify_n_pts_g5</th>\n",
       "      <th>classify_n_pts_g6</th>\n",
       "      <th>classify_n_pts_g7</th>\n",
       "      <th>complexity_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMM</td>\n",
       "      <td>17</td>\n",
       "      <td>fmalabe</td>\n",
       "      <td>1983</td>\n",
       "      <td>98</td>\n",
       "      <td>66</td>\n",
       "      <td>1516</td>\n",
       "      <td>1404</td>\n",
       "      <td>1305</td>\n",
       "      <td>1233</td>\n",
       "      <td>1183</td>\n",
       "      <td>1135</td>\n",
       "      <td>1079</td>\n",
       "      <td>1015</td>\n",
       "      <td>988</td>\n",
       "      <td>958</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1516</td>\n",
       "      <td>1404</td>\n",
       "      <td>1305</td>\n",
       "      <td>1233</td>\n",
       "      <td>1183</td>\n",
       "      <td>1135</td>\n",
       "      <td>1079</td>\n",
       "      <td>1015</td>\n",
       "      <td>988</td>\n",
       "      <td>958</td>\n",
       "      <td>1860</td>\n",
       "      <td>1792</td>\n",
       "      <td>1702</td>\n",
       "      <td>1646</td>\n",
       "      <td>1626</td>\n",
       "      <td>1578</td>\n",
       "      <td>1522</td>\n",
       "      <td>1474</td>\n",
       "      <td>1429</td>\n",
       "      <td>1419</td>\n",
       "      <td>124</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMM</td>\n",
       "      <td>17</td>\n",
       "      <td>ahzaidan</td>\n",
       "      <td>2249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2052</td>\n",
       "      <td>1974</td>\n",
       "      <td>1854</td>\n",
       "      <td>1774</td>\n",
       "      <td>1714</td>\n",
       "      <td>1678</td>\n",
       "      <td>1643</td>\n",
       "      <td>1611</td>\n",
       "      <td>1566</td>\n",
       "      <td>1516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2052</td>\n",
       "      <td>1974</td>\n",
       "      <td>1860</td>\n",
       "      <td>1780</td>\n",
       "      <td>1720</td>\n",
       "      <td>1684</td>\n",
       "      <td>1656</td>\n",
       "      <td>1632</td>\n",
       "      <td>1587</td>\n",
       "      <td>1527</td>\n",
       "      <td>2146</td>\n",
       "      <td>2092</td>\n",
       "      <td>2047</td>\n",
       "      <td>2007</td>\n",
       "      <td>1982</td>\n",
       "      <td>1952</td>\n",
       "      <td>1917</td>\n",
       "      <td>1909</td>\n",
       "      <td>1900</td>\n",
       "      <td>1900</td>\n",
       "      <td>67</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLR</td>\n",
       "      <td>17</td>\n",
       "      <td>dshemant</td>\n",
       "      <td>1457</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>1397</td>\n",
       "      <td>1365</td>\n",
       "      <td>1335</td>\n",
       "      <td>1311</td>\n",
       "      <td>1291</td>\n",
       "      <td>1267</td>\n",
       "      <td>1260</td>\n",
       "      <td>964</td>\n",
       "      <td>955</td>\n",
       "      <td>935</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1397</td>\n",
       "      <td>1365</td>\n",
       "      <td>1335</td>\n",
       "      <td>1311</td>\n",
       "      <td>1291</td>\n",
       "      <td>1267</td>\n",
       "      <td>1260</td>\n",
       "      <td>964</td>\n",
       "      <td>955</td>\n",
       "      <td>935</td>\n",
       "      <td>1443</td>\n",
       "      <td>1433</td>\n",
       "      <td>1430</td>\n",
       "      <td>1414</td>\n",
       "      <td>1414</td>\n",
       "      <td>1408</td>\n",
       "      <td>1408</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>1392</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLR</td>\n",
       "      <td>17</td>\n",
       "      <td>patamare</td>\n",
       "      <td>1225</td>\n",
       "      <td>261</td>\n",
       "      <td>78</td>\n",
       "      <td>777</td>\n",
       "      <td>727</td>\n",
       "      <td>676</td>\n",
       "      <td>640</td>\n",
       "      <td>630</td>\n",
       "      <td>588</td>\n",
       "      <td>574</td>\n",
       "      <td>558</td>\n",
       "      <td>540</td>\n",
       "      <td>530</td>\n",
       "      <td>103</td>\n",
       "      <td>29</td>\n",
       "      <td>777</td>\n",
       "      <td>727</td>\n",
       "      <td>676</td>\n",
       "      <td>640</td>\n",
       "      <td>630</td>\n",
       "      <td>588</td>\n",
       "      <td>574</td>\n",
       "      <td>558</td>\n",
       "      <td>540</td>\n",
       "      <td>530</td>\n",
       "      <td>1138</td>\n",
       "      <td>1074</td>\n",
       "      <td>1008</td>\n",
       "      <td>964</td>\n",
       "      <td>934</td>\n",
       "      <td>910</td>\n",
       "      <td>896</td>\n",
       "      <td>872</td>\n",
       "      <td>854</td>\n",
       "      <td>844</td>\n",
       "      <td>279</td>\n",
       "      <td>157</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLR</td>\n",
       "      <td>17</td>\n",
       "      <td>upooj</td>\n",
       "      <td>1995</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1942</td>\n",
       "      <td>1882</td>\n",
       "      <td>1702</td>\n",
       "      <td>1538</td>\n",
       "      <td>1513</td>\n",
       "      <td>1495</td>\n",
       "      <td>1110</td>\n",
       "      <td>1102</td>\n",
       "      <td>1093</td>\n",
       "      <td>1083</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1942</td>\n",
       "      <td>1882</td>\n",
       "      <td>1702</td>\n",
       "      <td>1538</td>\n",
       "      <td>1513</td>\n",
       "      <td>1495</td>\n",
       "      <td>1110</td>\n",
       "      <td>1102</td>\n",
       "      <td>1093</td>\n",
       "      <td>1083</td>\n",
       "      <td>1978</td>\n",
       "      <td>1962</td>\n",
       "      <td>1947</td>\n",
       "      <td>1939</td>\n",
       "      <td>1924</td>\n",
       "      <td>1924</td>\n",
       "      <td>1896</td>\n",
       "      <td>1888</td>\n",
       "      <td>1861</td>\n",
       "      <td>1861</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  node  week classify_userid  asin_count  ext.research_w_amz  \\\n",
       "0  AMM    17         fmalabe        1983                  98   \n",
       "1  AMM    17        ahzaidan        2249                   0   \n",
       "2  BLR    17        dshemant        1457                 123   \n",
       "3  BLR    17        patamare        1225                 261   \n",
       "4  BLR    17           upooj        1995                  16   \n",
       "\n",
       "   ext.research_wo_amz  cluster_g1  cluster_g2  cluster_g3  cluster_g4  \\\n",
       "0                   66        1516        1404        1305        1233   \n",
       "1                    0        2052        1974        1854        1774   \n",
       "2                    2        1397        1365        1335        1311   \n",
       "3                   78         777         727         676         640   \n",
       "4                   16        1942        1882        1702        1538   \n",
       "\n",
       "   cluster_g5  cluster_g6  cluster_g7  cluster_g8  cluster_g9  cluster_g10  \\\n",
       "0        1183        1135        1079        1015         988          958   \n",
       "1        1714        1678        1643        1611        1566         1516   \n",
       "2        1291        1267        1260         964         955          935   \n",
       "3         630         588         574         558         540          530   \n",
       "4        1513        1495        1110        1102        1093         1083   \n",
       "\n",
       "   unable_to_classify  invalid_NFA  cluster_wo_batch_g1  cluster_wo_batch_g2  \\\n",
       "0                   8            0                 1516                 1404   \n",
       "1                   0            0                 2052                 1974   \n",
       "2                  30            0                 1397                 1365   \n",
       "3                 103           29                  777                  727   \n",
       "4                  18            0                 1942                 1882   \n",
       "\n",
       "   cluster_wo_batch_g3  cluster_wo_batch_g4  cluster_wo_batch_g5  \\\n",
       "0                 1305                 1233                 1183   \n",
       "1                 1860                 1780                 1720   \n",
       "2                 1335                 1311                 1291   \n",
       "3                  676                  640                  630   \n",
       "4                 1702                 1538                 1513   \n",
       "\n",
       "   cluster_wo_batch_g6  cluster_wo_batch_g7  cluster_wo_batch_g8  \\\n",
       "0                 1135                 1079                 1015   \n",
       "1                 1684                 1656                 1632   \n",
       "2                 1267                 1260                  964   \n",
       "3                  588                  574                  558   \n",
       "4                 1495                 1110                 1102   \n",
       "\n",
       "   cluster_wo_batch_g9  cluster_wo_batch_g10  batch_pt_cluster_g1  \\\n",
       "0                  988                   958                 1860   \n",
       "1                 1587                  1527                 2146   \n",
       "2                  955                   935                 1443   \n",
       "3                  540                   530                 1138   \n",
       "4                 1093                  1083                 1978   \n",
       "\n",
       "   batch_pt_cluster_g2  batch_pt_cluster_g3  batch_pt_cluster_g4  \\\n",
       "0                 1792                 1702                 1646   \n",
       "1                 2092                 2047                 2007   \n",
       "2                 1433                 1430                 1414   \n",
       "3                 1074                 1008                  964   \n",
       "4                 1962                 1947                 1939   \n",
       "\n",
       "   batch_pt_cluster_g5  batch_pt_cluster_g6  batch_pt_cluster_g7  \\\n",
       "0                 1626                 1578                 1522   \n",
       "1                 1982                 1952                 1917   \n",
       "2                 1414                 1408                 1408   \n",
       "3                  934                  910                  896   \n",
       "4                 1924                 1924                 1896   \n",
       "\n",
       "   batch_pt_cluster_g8  batch_pt_cluster_g9  batch_pt_cluster_g10  \\\n",
       "0                 1474                 1429                  1419   \n",
       "1                 1909                 1900                  1900   \n",
       "2                 1392                 1392                  1392   \n",
       "3                  872                  854                   844   \n",
       "4                 1888                 1861                  1861   \n",
       "\n",
       "   classify_n_pts_g1  classify_n_pts_g2  classify_n_pts_g3  classify_n_pts_g4  \\\n",
       "0                124                 18                  2                  0   \n",
       "1                 67                 14                  0                  0   \n",
       "2                147                  3                  0                  0   \n",
       "3                279                157                 52                  7   \n",
       "4                 46                  0                  0                  0   \n",
       "\n",
       "   classify_n_pts_g5  classify_n_pts_g6  classify_n_pts_g7  complexity_h  \n",
       "0                  0                  0                  0           795  \n",
       "1                  0                  0                  0          1055  \n",
       "2                  0                  0                  0           321  \n",
       "3                  0                  0                  0           500  \n",
       "4                  0                  0                  0           395  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivoting the final dataset using groupby for EDA.\n",
    "\n",
    "df_eda_table = df.groupby(by=['node','week','classify_userid'],sort=False)[['asin_count','ext.research_w_amz', \n",
    "        'ext.research_wo_amz','cluster_g1',\n",
    "       'cluster_g2', 'cluster_g3', 'cluster_g4', 'cluster_g5', 'cluster_g6',\n",
    "       'cluster_g7', 'cluster_g8', 'cluster_g9', 'cluster_g10','unable_to_classify','invalid_NFA',\n",
    "        'cluster_wo_batch_g1', 'cluster_wo_batch_g2', 'cluster_wo_batch_g3',\n",
    "       'cluster_wo_batch_g4', 'cluster_wo_batch_g5', 'cluster_wo_batch_g6',\n",
    "       'cluster_wo_batch_g7', 'cluster_wo_batch_g8', 'cluster_wo_batch_g9',\n",
    "       'cluster_wo_batch_g10','batch_pt_cluster_g1', 'batch_pt_cluster_g2', 'batch_pt_cluster_g3',\n",
    "       'batch_pt_cluster_g4', 'batch_pt_cluster_g5', 'batch_pt_cluster_g6',\n",
    "       'batch_pt_cluster_g7', 'batch_pt_cluster_g8', 'batch_pt_cluster_g9',\n",
    "       'batch_pt_cluster_g10','classify_n_pts_g1','classify_n_pts_g2', 'classify_n_pts_g3', 'classify_n_pts_g4',\n",
    "       'classify_n_pts_g5','classify_n_pts_g6', 'classify_n_pts_g7','complexity_h']].sum().reset_index()\n",
    "\n",
    "df_eda_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda_table = pd.merge(left=df_eda_table, right=df_mp_pivot,how='inner')\n",
    "\n",
    "column_names = ['node', 'week', 'classify_userid', 'mp', 'no_of_mp', 'asin_count', 'ext.research_w_amz',\n",
    "       'ext.research_wo_amz', 'cluster_g1', 'cluster_g2', 'cluster_g3',\n",
    "       'cluster_g4', 'cluster_g5', 'cluster_g6', 'cluster_g7', 'cluster_g8',\n",
    "       'cluster_g9', 'cluster_g10', 'unable_to_classify', 'invalid_NFA',\n",
    "       'cluster_wo_batch_g1', 'cluster_wo_batch_g2', 'cluster_wo_batch_g3',\n",
    "       'cluster_wo_batch_g4', 'cluster_wo_batch_g5', 'cluster_wo_batch_g6',\n",
    "       'cluster_wo_batch_g7', 'cluster_wo_batch_g8', 'cluster_wo_batch_g9',\n",
    "       'cluster_wo_batch_g10','batch_pt_cluster_g1', 'batch_pt_cluster_g2', 'batch_pt_cluster_g3',\n",
    "       'batch_pt_cluster_g4', 'batch_pt_cluster_g5', 'batch_pt_cluster_g6',\n",
    "       'batch_pt_cluster_g7', 'batch_pt_cluster_g8', 'batch_pt_cluster_g9',\n",
    "       'batch_pt_cluster_g10','classify_n_pts_g1', 'classify_n_pts_g2', 'classify_n_pts_g3',\n",
    "       'classify_n_pts_g4', 'classify_n_pts_g5', 'classify_n_pts_g6',\n",
    "       'classify_n_pts_g7','complexity_h']\n",
    "\n",
    "df_eda_table = df_eda_table.reindex(columns=column_names)\n",
    "\n",
    "for i in df_eda_table.columns[6:]:\n",
    "    df_eda_table[i+'%'] = (df_eda_table[i]/df_eda_table['asin_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLR    510\n",
       "AMM     59\n",
       "SZX     23\n",
       "Name: node, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BLR    0.861\n",
       "AMM    0.100\n",
       "SZX    0.039\n",
       "Name: node, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_eda_table.node.value_counts())\n",
    "display(round(df_eda_table.node.value_counts(normalize=True),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['node', 'week', 'classify_userid', 'mp', 'no_of_mp', 'asin_count',\n",
       "       'ext.research_w_amz', 'ext.research_wo_amz', 'cluster_g1', 'cluster_g2',\n",
       "       'cluster_g3', 'cluster_g4', 'cluster_g5', 'cluster_g6', 'cluster_g7',\n",
       "       'cluster_g8', 'cluster_g9', 'cluster_g10', 'unable_to_classify',\n",
       "       'invalid_NFA', 'cluster_wo_batch_g1', 'cluster_wo_batch_g2',\n",
       "       'cluster_wo_batch_g3', 'cluster_wo_batch_g4', 'cluster_wo_batch_g5',\n",
       "       'cluster_wo_batch_g6', 'cluster_wo_batch_g7', 'cluster_wo_batch_g8',\n",
       "       'cluster_wo_batch_g9', 'cluster_wo_batch_g10', 'batch_pt_cluster_g1',\n",
       "       'batch_pt_cluster_g2', 'batch_pt_cluster_g3', 'batch_pt_cluster_g4',\n",
       "       'batch_pt_cluster_g5', 'batch_pt_cluster_g6', 'batch_pt_cluster_g7',\n",
       "       'batch_pt_cluster_g8', 'batch_pt_cluster_g9', 'batch_pt_cluster_g10',\n",
       "       'classify_n_pts_g1', 'classify_n_pts_g2', 'classify_n_pts_g3',\n",
       "       'classify_n_pts_g4', 'classify_n_pts_g5', 'classify_n_pts_g6',\n",
       "       'classify_n_pts_g7', 'complexity_h', 'ext.research_w_amz%',\n",
       "       'ext.research_wo_amz%', 'cluster_g1%', 'cluster_g2%', 'cluster_g3%',\n",
       "       'cluster_g4%', 'cluster_g5%', 'cluster_g6%', 'cluster_g7%',\n",
       "       'cluster_g8%', 'cluster_g9%', 'cluster_g10%', 'unable_to_classify%',\n",
       "       'invalid_NFA%', 'cluster_wo_batch_g1%', 'cluster_wo_batch_g2%',\n",
       "       'cluster_wo_batch_g3%', 'cluster_wo_batch_g4%', 'cluster_wo_batch_g5%',\n",
       "       'cluster_wo_batch_g6%', 'cluster_wo_batch_g7%', 'cluster_wo_batch_g8%',\n",
       "       'cluster_wo_batch_g9%', 'cluster_wo_batch_g10%', 'batch_pt_cluster_g1%',\n",
       "       'batch_pt_cluster_g2%', 'batch_pt_cluster_g3%', 'batch_pt_cluster_g4%',\n",
       "       'batch_pt_cluster_g5%', 'batch_pt_cluster_g6%', 'batch_pt_cluster_g7%',\n",
       "       'batch_pt_cluster_g8%', 'batch_pt_cluster_g9%', 'batch_pt_cluster_g10%',\n",
       "       'classify_n_pts_g1%', 'classify_n_pts_g2%', 'classify_n_pts_g3%',\n",
       "       'classify_n_pts_g4%', 'classify_n_pts_g5%', 'classify_n_pts_g6%',\n",
       "       'classify_n_pts_g7%', 'complexity_h%'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 8, 9, 5, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['AE,UK', 'UK', 'US', 'SG', 'CA', 'AU', 'AE', 'MX', 'BR', 'JP',\n",
       "       'CA,DE,ES,FR,IT,MX,UK,US', 'CA,DE,ES,FR,IT,MX,SG,UK,US',\n",
       "       'DE,ES,FR,IT,UK', 'ES', 'DE,ES,FR,IT'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_eda_table.columns)\n",
    "display(df_eda_table.no_of_mp.unique())\n",
    "display(df_eda_table.mp.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken till this is 2.97 mins\n"
     ]
    }
   ],
   "source": [
    "# Captures the time taken for the code execution\n",
    "\n",
    "mid2 = time.time()\n",
    "overall_time_taken = ((mid2-start)/60)\n",
    "print(f'Time taken till this is {round(overall_time_taken,2)} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the file for EDA\n",
    "# export_start = time.time()\n",
    "\n",
    "#df_eda_table.to_csv('C:/Users/sivapr/Documents/Cops/ML Project/PC MC TPH Model/Chunking Base files/df_eda_table.csv',index=False)\n",
    "df.to_csv(\"C:/Users/sivapr/Documents/Cops/ML Project/PC MC TPH Model/Chunking Base files/PC_MC_RD_(Wk'09-Wk'23)_Processed.csv\",index=False)\n",
    "\n",
    "# export_end = time.time()\n",
    "# export_time_taken = ((mid2-start)/60)\n",
    "# print(f'Time taken to export the file is {round(export_time_taken,2)} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall time taken is 3.69 mins\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "overall_time_taken = ((end-start)/60)\n",
    "print(f'Overall time taken is {round(overall_time_taken,2)} mins')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
